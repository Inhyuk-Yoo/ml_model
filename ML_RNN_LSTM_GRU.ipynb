{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML1_RNN.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPge4oA7fkjozkKXXffg5QH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"YbA1vOqiPrVv"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kKWy051PxgN"},"source":["%cd /content/gdrive/MyDrive/2021_2학기/기계학습"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzSapLLdPzu6"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Yt2rZyJP0nJ"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IO7U_6wWP4rg"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xWk04J6P5Ef"},"source":["train_data = pd.read_csv('./data/train.csv', encoding = 'utf-8')\n","test_data = pd.read_csv('./data/test.csv', encoding = 'utf-8')\n","train_data.drop_duplicates(subset=['mail'], inplace=True)\n","\n","label_data = train_data['label']\n","mail_data = train_data['mail']\n","mail_test = test_data['mail']\n","mail_train, mail_cv, label_train, label_cv = train_test_split(mail_data, label_data, test_size=0.2, random_state=0, stratify=label_data)\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(mail_train)\n","mail_train_encoded = tokenizer.texts_to_sequences(mail_train)\n","word_to_index = tokenizer.word_index\n","vocab_size = len(word_to_index) + 1\n","max_len = max(len(l) for l in mail_train_encoded)\n","mail_train_padded = pad_sequences(mail_train_encoded, maxlen = max_len)\n","\n","# tokenizer = Tokenizer()\n","# tokenizer.fit_on_texts(mail_cv)\n","mail_cv_encoded = tokenizer.texts_to_sequences(mail_cv)\n","mail_cv_padded = pad_sequences(mail_cv_encoded, maxlen = max_len)\n","\n","# tokenizer = Tokenizer()\n","# tokenizer.fit_on_texts(mail_test)\n","mail_test_encoded = tokenizer.texts_to_sequences(mail_test)\n","max_len_test = max(len(l) for l in mail_test_encoded)\n","mail_test_padded = pad_sequences(mail_test_encoded, maxlen = max_len_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQV2XY50P58g"},"source":["from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, GRU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras import backend as K\n","\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, 32))\n","# model.add(SimpleRNN(32))\n","# model.add(LSTM(32))\n","model.add(GRU(32))\n","model.add(Dense(1, activation='sigmoid'))\n","# model.add(Dense(1, activation='softmax'))\n","\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', f1_m, precision_m, recall_m])\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_f1_m', mode='max', verbose=1, save_best_only=True)\n","history = model.fit(mail_train_padded, label_train, epochs=10, batch_size=64, callbacks=[es, mc], validation_split=0.23)\n","\n","loss, accuracy, f1_score, precision, recall = model.evaluate(mail_cv_padded, label_cv, batch_size=64, verbose=0)\n","print('loss: ', loss)\n","# print(loss)\n","print('accuracy: ', accuracy)\n","# print(accuracy)\n","print('f1_score: ', f1_score)\n","# print(f1_score)\n","print('precision: ', precision)\n","# print(precision)\n","print('recall: ', recall)\n","# print(recall)\n","\n","prediction = model.predict(mail_test_padded, batch_size=64)\n","for idx, p in enumerate(prediction):\n","    if p > 0.5 :\n","        prediction[idx] = bool(1)\n","    else :\n","        prediction[idx] = bool(0)\n","\n","submission = pd.read_csv('./result.csv', encoding = 'utf-8')\n","submission['label'] = prediction\n","submission[['label']]=submission[['label']].astype(int)\n","submission.to_csv('./submissionRnn2.csv', index=False)\n","# submission.info()\n","\n","epochs = range(1, len(history.history['acc']) + 1)\n","plt.plot(epochs, history.history['loss'])\n","plt.plot(epochs, history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n","\n","epochs = range(1, len(history.history['acc']) + 1)\n","plt.plot(epochs, history.history['acc'])\n","plt.plot(epochs, history.history['val_acc'])\n","plt.title('model acc')\n","plt.ylabel('acc')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrSjU5veQs3i"},"source":[""],"execution_count":null,"outputs":[]}]}